# Random Forest - תשובות

## האם מודל Random Forest פותר בעיית קלסיפיקציה, רגרסיה או גם וגם?
**תשובה:**  
Random Forest מתאים גם לקלסיפיקציה וגם לרגרסיה, בדומה ל‑Decision Tree.

---

## מהו הרעיון המרכזי שעליו מבוסס מודל Random Forest? כיצד Random Forest קשור למודל Decision Tree?
**תשובה:**  
Random Forest בונה הרבה עצי החלטה (Decision Trees) בלתי תלויים במעט אקראיות ומאחד את תחזיותיהם.  
כל עץ הוא מעין Decision Tree עצמאי — אך שונה מהאחרים בגלל אקראיות בדאטה ובבחירת התכונות — והיער מקבל "ממוצע חכם" או הצבעה מרובה שמייצבת ומשפרת את הדיוק והכללה.

---

## מהו Bootstrap Sampling וכיצד הוא משמש ב‑Random Forest?
**תשובה:**  
Bootstrap Sampling = דגימה באקראי עם החזרה מהאוכלוסייה (sample with replacement).  
לכל עץ בוחרים מדגם Bootstrap שונה מהאימון; חלק מהדוגמאות יחזרו במדגם, וחלק לא ייכללו. כך כל עץ מאומן על תת‑קבוצה שונה של הנתונים, מה שיוצר גיוון בין העצים.

---

## מדוע השימוש באקראיות משפר את ביצועי המודל?
**תשובה:**  
אם כל העצים היו זהים — שגיאותיהם היו מושרשות ודומות. הכנסת אקראיות (בדגימה ובבחירת תכונות) גורמת לכך שכל עץ יתרכז בהיבטים מעט שונים של הבעיה, ולכן השגיאות אינן תלויות זו בזו. כאשר מאחדים את התחזיות, שגיאות פרטניות נוטות להתבטל והתחזית הסופית יציבה ומדויקת יותר.

---

## כיצד מתקבלת התחזית הסופית ב‑Random Forest לקלסיפיקציה? מהו מנגנון ההצבעה (Voting)?
**תשובה:**  
כל עץ נותן סיווג משלו. התחזית הסופית היא המחלקה שקיבלה את מרבית הקולות (Majority Vote).  
כמו כן אפשר להפיק "הסתברות" על‑ידי חישוב אחוז העצים שבחרו בכל מחלקה.

---

## כיצד מתקבלת התחזית הסופית ב‑Random Forest לרגרסיה?
**תשובה:**  
כל עץ חוזה ערך מספרי; התחזית הסופית היא הממוצע של כל התחזיות מהעצים (mean of predictions).

---

## אילו Hyperparameters נפוצים קיימים במודל Random Forest?
**תשובה:**  
- n_estimators — מספר העצים ביער.  
- max_depth — עומק מקסימלי לכל עץ.  
- min_samples_split — מינימום דוגמאות הדרוש לפיצול צומת.  
- min_samples_leaf — מינימום דוגמאות בעלה.  
- max_features — מספר/חלק התכונות המוגרלות בכל פיצול.  
- bootstrap — האם להשתמש ב‑Bootstrap Sampling (True/False).

---

## מהו OOB Error (Out‑Of‑Bag Error) וכיצד משתמשים בו להערכת ביצועי המודל?
**תשובה:**  
עבור כל עץ יש דוגמאות שלא נבחרו במדגם ה‑Bootstrap שלו — אלו דוגמאות ה‑OOB עבור אותו עץ. אפשר להשתמש בהן כסט בדיקה פנימי: להעריך את שגיאת החיזוי של העץ על הדוגמאות שלא ראו באימון שלו, ואז לאגד על פני כל העצים לקבלת OOB Error. זוהי הערכה טובה של ביצועי המודל בלי צורך בחציית Train/Test נפרדת.

---

## מה היתרון של Random Forest מבחינת יציבות המודל לעומת Decision Tree?
**תשובה:**  
Decision Tree בודד רגיש לשינויים קטנים בנתונים ועלול להיות מועמד ל‑overfitting. Random Forest, שמאחד הרבה עצים שונים, הרבה יותר יציב: שינוי קטן בנתונים משפיע רק על תת‑קבוצה של עצים ולא על כל המודל, ולכן הביצועים יהיו עקביים יותר ופחות רגישים לרעש.

---

## אילו מדדי ביצוע מתאימים להערכת מודל Random Forest?
**תשובה:**  
לקלסיפיקציה:  
- Accuracy  
- Precision, Recall, F1‑score  
- Confusion Matrix

לרגרסיה:  
- MSE (Mean Squared Error)  
- RMSE (Root Mean Squared Error)  
- MAE (Mean Absolute Error)  
- R² 

---
