# Random Forest - תשובות

 האם מודל Random Forest פותר בעיית קלסיפיקציה, רגרסיה או גם וגם?

**תשובה:**  
Random Forest מתאים גם לקלסיפיקציה וגם לרגרסיה, בדומה ל‑Decision Tree.

---

 מהו הרעיון המרכזי שעליו מבוסס מודל Random Forest? כיצד Random Forest קשור למודל Decision Tree?

**תשובה:**  
Random Forest בונה הרבה עצי החלטה (Decision Trees) בלתי תלויים במעט אקראיות ומאחד את תחזיותיהם.  
כל עץ הוא מעין Decision Tree עצמאי — אך שונה מהאחרים בגלל אקראיות בדאטה ובבחירת התכונות — והיער מקבל "ממוצע חכם" או הצבעה מרובה שמייצבת ומשפרת את הדיוק והכללה.

---

 מהו Bootstrap Sampling וכיצד הוא משמש ב‑Random Forest?

**תשובה:**  
Bootstrap Sampling = דגימה באקראי עם החזרה מהאוכלוסייה (sample with replacement).  
לכל עץ בוחרים מדגם Bootstrap שונה מהאימון; חלק מהדוגמאות יחזרו במדגם, וחלק לא ייכללו. כך כל עץ מאומן על תת‑קבוצה שונה של הנתונים, מה שיוצר גיוון בין העצים.

---

 מדוע השימוש באקראיות משפר את ביצועי המודל?

**תשובה:**  
אם כל העצים היו זהים — שגיאותיהם היו מושרשות ודומות. הכנסת אקראיות (בדגימה ובבחירת תכונות) גורמת לכך שכל עץ יתרכז בהיבטים מעט שונים של הבעיה, ולכן השגיאות אינן תלויות זו בזו. כאשר מאחדים את התחזיות, שגיאות פרטניות נוטות להתבטל והתחזית הסופית יציבה ומדויקת יותר.

---

כיצד מתקבלת התחזית הסופית ב־Random Forest לקלסיפיקציה?  
מהו מנגנון ההצבעה (Voting) ב־Random Forest וכיצד הוא פועל? 

**תשובה:**  
כל עץ נותן סיווג משלו. התחזית הסופית היא המחלקה שקיבלה את מרבית הקולות (Majority Vote).  
כמו כן אפשר להפיק "הסתברות" על‑ידי חישוב אחוז העצים שבחרו בכל מחלקה.

---

 כיצד מתקבלת התחזית הסופית ב‑Random Forest לרגרסיה?

**תשובה:**  
כל עץ חוזה ערך מספרי; התחזית הסופית היא הממוצע של כל התחזיות מהעצים (mean of predictions).

---

 אילו Hyperparameters נפוצים קיימים במודל Random Forest?

**תשובה:**  
- n_estimators — מספר העצים ביער.  
- max_depth — עומק מקסימלי לכל עץ.  
- min_samples_split — מינימום דוגמאות הדרוש לפיצול צומת.  
- min_samples_leaf — מינימום דוגמאות בעלה.  
- max_features — מספר/חלק התכונות המוגרלות בכל פיצול.  
- bootstrap — האם להשתמש ב‑Bootstrap Sampling (True/False).

---

 מהו OOB Error (Out‑Of‑Bag Error) וכיצד משתמשים בו להערכת ביצועי המודל?

**תשובה:**  
עבור כל עץ יש דוגמאות שלא נבחרו במדגם ה‑Bootstrap שלו — אלו דוגמאות ה‑OOB עבור אותו עץ. אפשר להשתמש בהן כסט בדיקה פנימי: להעריך את שגיאת החיזוי של העץ על הדוגמאות שלא ראו באימון שלו, ואז לאגד על פני כל העצים לקבלת OOB Error. זוהי הערכה טובה של ביצועי המודל בלי צורך בחציית Train/Test נפרדת.

---

 מה היתרון של Random Forest מבחינת יציבות המודל לעומת Decision Tree?

**תשובה:**  
עץ החלטה אחד לרוב "לומד בעל פה" את נתוני האימון (overfitting) ורגיש מאוד: שינוי קטן בנתונים יכול לשנות את כל העץ.  
Random Forest הרבה יותר יציב כי הוא בנוי ממאות עצים שונים (בזכות דגימה אקראית של הנתונים ובחירה אקראית של שאלות בכל עץ). 
הטעויות של עץ אחד מתקזזות עם הטעויות של האחרים כשמצביעים או מממוצעים את התשובות, ושינוי קטן בנתונים משפיע רק על חלק מהעצים.  

---

אילו מדדי ביצוע מתאימים להערכת מודל Random Forest בקלסיפיקציה וברגרסיה?

**תשובה:**  
לקלסיפיקציה:  
- Accuracy  
- Precision, Recall, F1‑score  
- Confusion Matrix

לרגרסיה:  
- MSE (Mean Squared Error)  
- RMSE (Root Mean Squared Error)  
- MAE (Mean Absolute Error)  
- R²

ניתן להיעזר ב-OOB Score/Error כמדד פנימי טוב להערכת הכללה, ללא צורך ב-validation set נפרד.


---
