# KNN – תשובות

---

האם האלגוריתם KNN פותר בעיית קלסיפיקציה, רגרסיה או גם וגם?

**תשובה:**  
גם וגם (קלסיפיקציה וגם רגרסיה).

---

מה המשמעות של השם KNN?

**תשובה:**  
K-Nearest Neighbors = K השכנים הקרובים ביותר.

---

מהו הרעיון המרכזי שעליו מבוסס האלגוריתם KNN?

**תשובה:**  
דוגמה חדשה מקבלת תשובה לפי הדוגמאות הכי דומות/קרובות אליה בנתונים.

---

מהו התפקיד של הפרמטר K באלגוריתם?

**תשובה:**  
קובע כמה שכנים נבדוק כדי להחליט את התחזית.

---

האם K נחשב Hyperparameter? הסבר/י

**תשובה:**  
כן. הוא נקבע מראש ולא נלמד מהנתונים.

---

כיצד בחירת ערך קטן של K משפיעה על המודל?

**תשובה:**  
המודל נהיה רגיש לרעש (Overfitting) ותלוי מאוד בנקודות בודדות.

---

כיצד בחירת ערך גדול של K משפיעה על המודל?

**תשובה:**  
המודל נעשה “מוחלק” מדי (Underfitting) ופחות רגיש לדפוסים מקומיים.

---

בכדי למדוד את ה- K האידיאלי נשתמש בגרף ה ELBOW  
הסבר מה זה גרף ELBOW? מה בד"כ יש בציר ה- X וציר ה- Y?  
כיצד נבחר את ה- Sweet Spot?  
תן דוגמא לעוד מודל ששם נשתמש בגרף זה והסבר כיצד?

**תשובה:**  
גרף Elbow מציג איך ביצועי המודל משתנים כשמשנים פרמטר (כאן: K).  
בדרך כלל:  
- ציר X: ערכי K (1,2,3,...)  
- ציר Y: מדד טעות/ביצועים (למשל Error או 1-Accuracy)  
ה־Sweet Spot הוא הנקודה שבה השיפור נהיה קטן — “השבר” בגרף.  
דוגמה נוספת: ב־K-Means משתמשים בגרף זה כדי לבחור את מספר התוצאות K.
---

מה ההבדל בין KNN לקלסיפיקציה לבין KNN לרגרסיה?

**תשובה:**  
בקלסיפיקציה מחזירים מחלקה, וברגרסיה מחזירים ערך מספרי.

---

כיצד מתקבלת התחזית ב־KNN לקלסיפיקציה?

**תשובה:**  
מצביעים על המחלקה הכי נפוצה בין K השכנים.

---

כיצד מתקבלת התחזית ב־KNN לרגרסיה?

**תשובה:**  
מחשבים ממוצע של הערכים של K השכנים.

---

איזו מדידת מרחק נפוצה משמשת ב־KNN?

**תשובה:**  
מרחק אוקלידי (Euclidean).

---

כיצד מספר הפיצ'רים משפיע על ביצועי KNN?

**תשובה:**  
ככל שיש יותר פיצ'רים, קשה יותר למדוד “קרבה” בצורה טובה, ולכן הביצועים יכולים לרדת.

---

האם קיים שלב אימון (Training) מובהק באלגוריתם KNN?

**תשובה:**  
לא ממש. הוא בעיקר שומר את הנתונים, והחישוב העיקרי קורה בזמן חיזוי.

---

כיצד Python פותר את חישוב KNN – האם באמצעות נוסחה סגורה או באמצעות חישוב ישיר בזמן החיזוי?

**תשובה:**  
באמצעות חישוב ישיר בזמן החיזוי: מחשבים מרחקים לשכנים ובוחרים את הקרובים.

---

מהם היתרונות המרכזיים של KNN?

**תשובה:**  
פשוט להבנה, אין אימון מורכב, עובד טוב כשיש דפוסים מקומיים והרבה נתונים.

---

מהם החסרונות המרכזיים של KNN?

**תשובה:**  
איטי בחיזוי על דאטה גדול, רגיש לסקייל של פיצ'רים, מושפע מרעש וממימדיות גבוהה.

---
