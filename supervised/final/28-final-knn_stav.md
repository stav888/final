# KNN

האם האלגוריתם KNN פותר בעיית קלסיפיקציה, רגרסיה או גם וגם?

**תשובה:**

ה KNN יכול לפתור גם קלסיפיקציה וגם רגרסיה. הוא אלגוריתם גמיש שמשמש בעיקר לסיווג, אבל עובד מצוין גם לחיזוי ערכים רציפים.

---

מה המשמעות של השם KNN?

**תשובה:**

ה KNN = K Nearest Neighbors, כלומר “K השכנים הקרובים ביותר”. הרעיון הוא להסתכל על K (מספר) הדגימות הכי קרובות לנקודה החדשה.

---

מהו הרעיון המרכזי שעליו מבוסס האלגוריתם KNN?

**תשובה:**

נקודות הדומות זו לזו במרחב הפיצ'רים - כלומר מרוחקות זו מזו מעט - בדרך כלל מקבלות תוצאה זהה. כדי לנבא ערך עבור נקודה חדשה מזהים את השכנים הקרובים לה ומסתמכים עליהם לקבלת ההחלטה.

---

מהו התפקיד של הפרמטר K באלגוריתם?

**תשובה**: K קובע כמה שכנים קרובים נכניס לחישוב הניבוי. לדוגמה: אם K=3, מסתכלים על 3 הנקודות הקרובות ביותר לנקודה החדשה.

---

האם K נחשב Hyperparameter? הסבר/י

**תשובה:**

כן, K הוא Hyperparameter כי אנחנו בוחרים אותו מראש (לפני הריצה), והוא לא נלמד מהדאטה כמו משקולות/מקדמים. שינוי של K משנה ישירות את התנהגות המודל ואת התוצאות.

---

כיצד בחירת ערך קטן של K משפיעה על המודל?

**תשובה:**
ערך K גדול הופך את המודל לחלק יותר ויציב – הוא מתעלם מרעש ומפרטים קטנים, אם הקפיצה ל-K גבוהה מדי, המודל ממוצע עד כדי כך שהוא מפספס את הדפוסים האמיתיים ונופל ל-underfitting.

---

כיצד בחירת ערך גדול של K משפיעה על המודל?

**תשובה:**

---

בכדי למדוד את ה- K האידיאלי נשתמש בגרף ה ELBOW  
הסבר מה זה גרף ELBOW? מה בד"כ יש בציר ה- X וציר ה- Y?  
כיצד נבחר את ה- Sweet Spot?  
תן דוגמא לעוד מודל ששם נשתמש בגרף זה והסבר כיצד?  

---

מה ההבדל בין KNN לקלסיפיקציה לבין KNN לרגרסיה?

---

כיצד מתקבלת התחזית ב־KNN לקלסיפיקציה?

---

כיצד מתקבלת התחזית ב־KNN לרגרסיה?

---

איזו מדידת מרחק נפוצה משמשת ב־KNN?

---

כיצד מספר הפיצ'רים משפיע על ביצועי KNN?

---

האם קיים שלב אימון (Training) מובהק באלגוריתם KNN?

---

כיצד Python פותר את חישוב KNN – האם באמצעות נוסחה סגורה או באמצעות חישוב ישיר בזמן החיזוי?

---

מהם היתרונות המרכזיים של KNN?

---

מהם החסרונות המרכזיים של KNN?

---
