# KNN

האם האלגוריתם KNN פותר בעיית קלסיפיקציה, רגרסיה או גם וגם?

**תשובה:**

ה KNN יכול לפתור גם קלסיפיקציה וגם רגרסיה. הוא אלגוריתם גמיש שמשמש בעיקר לסיווג, אבל עובד מצוין גם לחיזוי ערכים רציפים.

---

מה המשמעות של השם KNN?

**תשובה:**

ה KNN = K Nearest Neighbors, כלומר “K השכנים הקרובים ביותר”. הרעיון הוא להסתכל על K (מספר) הדגימות הכי קרובות לנקודה החדשה.

---

מהו הרעיון המרכזי שעליו מבוסס האלגוריתם KNN?

**תשובה:**

נקודות הדומות זו לזו במרחב הפיצ'רים - כלומר מרוחקות זו מזו מעט - בדרך כלל מקבלות תוצאה זהה. כדי לנבא ערך עבור נקודה חדשה מזהים את השכנים הקרובים לה ומסתמכים עליהם לקבלת ההחלטה.

---

מהו התפקיד של הפרמטר K באלגוריתם?

**תשובה**: K קובע כמה שכנים קרובים נכניס לחישוב הניבוי. לדוגמה: אם K=3, מסתכלים על 3 הנקודות הקרובות ביותר לנקודה החדשה.

---

האם K נחשב Hyperparameter? הסבר/י

**תשובה:**

כן, K הוא Hyperparameter כי אנחנו בוחרים אותו מראש (לפני הריצה), והוא לא נלמד מהדאטה כמו משקולות/מקדמים. שינוי של K משנה ישירות את התנהגות המודל ואת התוצאות.

---

כיצד בחירת ערך קטן של K משפיעה על המודל?

**תשובה:**

ערך K נמוך (למשל 1 או 3) גורם לכך שהמודל יהיה גמיש בצורה יתרה ויקלוט כל שינוי קטן בנתונים, הוא מתאים מאוד לנתוני האימון, אבל רגיש לרעש ויכול לגרום ל-overfitting.

---

כיצד בחירת ערך גדול של K משפיעה על המודל?

**תשובה:**

ערך K גדול הופך את המודל לחלק יותר ויציב – הוא מתעלם מרעש ומפרטים קטנים, אם הקפיצה ל-K גבוהה מדי, המודל ממוצע עד כדי כך שהוא מפספס את הדפוסים האמיתיים ונופל ל-underfitting.

---

בכדי למדוד את ה- K האידיאלי נשתמש בגרף ה ELBOW  
הסבר מה זה גרף ELBOW? מה בד"כ יש בציר ה- X וציר ה- Y?  
כיצד נבחר את ה- Sweet Spot?  
תן דוגמא לעוד מודל ששם נשתמש בגרף זה והסבר כיצד?  

**תשובה:**

גרף המרפק (Elbow) מראה איך הביצועים משתפרים ככל שמעלים את הערך של הפרמטר, עד לנקודה שבה השיפור כמעט פוסק.

ציר ה-X בדרך כלל יציג את הערך של הפרמטר שאנחנו בודקים (למשל, ב-KNN זה יהיה ה-K). <BR>
ציר ה-Y יציג מדד ביצוע או שגיאה: ברגרסיה לעיתים MSE, בקלסיפיקציה Accuracy או Error.  <BR>

איך בוחרים Sweet Spot? <BR> 
מחפשים את “המרפק” – המקום שבו עד אליו יש שיפור משמעותי, וממנו והלאה השיפור כבר קטן ולא מצדיק עוד שינוי בפרמטר.<BR>

דוגמא למודל נוסף שמשתמש בגרף זה: <BR> 
ב-K-Means Clustering נבחן גרף ELBOW כדי למצוא את מספר הקבוצות K המתאים. בציר ה-Y מצוין Within-Cluster Sum of Squares, בציר ה-X מספר הקבוצות. הנקודה שבה הגרף מתקף ויורד בחדות פחות מסמנת את K האידיאלי. <BR>

---

מה ההבדל בין KNN לקלסיפיקציה לבין KNN לרגרסיה?

**תשובה:**

---

כיצד מתקבלת התחזית ב־KNN לקלסיפיקציה?

**תשובה:**

---

כיצד מתקבלת התחזית ב־KNN לרגרסיה?

**תשובה:**

---

איזו מדידת מרחק נפוצה משמשת ב־KNN?

**תשובה:**

---

כיצד מספר הפיצ'רים משפיע על ביצועי KNN?

**תשובה:**

---

האם קיים שלב אימון (Training) מובהק באלגוריתם KNN?

**תשובה:**

---

כיצד Python פותר את חישוב KNN – האם באמצעות נוסחה סגורה או באמצעות חישוב ישיר בזמן החיזוי?

**תשובה:**

---

מהם היתרונות המרכזיים של KNN?

**תשובה:**

---

מהם החסרונות המרכזיים של KNN?

**תשובה:**

---
